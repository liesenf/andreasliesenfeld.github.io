<font color="red">&#9733;&#9733;&#9733; Upcoming: Looking forward to presenting at ECCA2020 and CLSW2020 this summer. &#9733;&#9733;&#9733;</font><br />

<p><img src="pic.jpg" alt="Picture" style="float:left;border:2;margin-right: 20px;">

I am a conversation analyst with a background in data science. I develop tools for <a href="https://chatbotslife.com/what-is-conversation-design-4cfe7ed200ea">conversation design</a> and voice bots. I also write about human-technology interaction inspired by <a href="https://en.wikipedia.org/wiki/Process_philosophy">process philosophy</a>. Late naturalist under pressure. "You must collect things for reasons you don’t yet understand." —<a href="https://www.google.com/search?q=daniel+boorstin+quotes&oq=daniel+boorstin+quotes">Daniel J. Boorstin</a> 
<br />
<br />
<b>Email:</b> <br> 
lies0002[AT]ntu[DOT]edu[DOT]sg<br>

<br />

<b>Research:</b> <br>
My research interests originate in the study of human-human conversation and story-telling based on video-recordings. Then I became interested in how voice bots can participate in these activities. How can we design voice user interfaces that can hold up their end of conversations? Increasingly, I am also interested in speech processing to detect and model various aspects of conversational and social intelligence such as stance, rapport and humor. What resources and pipelines would enable voice bots to interact with humans in more human-like ways? 
My current work focuses on <a href="https://liesenf.github.io/talking-chinese-characters">voice user interface design</a> and the development of <a href="https://liesenf.github.io/beyond-words-asr">tools and methods to advance conversation design</a>. During grad school I conducted linguistic fieldwork in different parts of Asia, built a video corpus of Malaysian Cantonese, and worked on the development of cognitive grammars and framenets for language technology. <br />

I also work as a conversation design consultant in the Greater Bay Area and currently write a book chapter on crowd-sourcing talk for voice technology.<br />

<br />

My <a href="https://en.wikipedia.org/wiki/Erd%C5%91s_number">Erdős number</a> is 0.<br />
<br />
<b>Experience:</b> <br>
Postdoctoral Research Fellow, Linguistics Theory and Language Technology group (<a href="http://llt.cbs.polyu.edu.hk/">LTT</a>), The Hong Kong Polytechnic University, Hong Kong.<br>
PhD researcher, Nanyang Technological University, Singapore<br>
Visiting fellow, Computational Linguistics, Düsseldorf University, Germany<br>
Data scientist, Industry, Berlin, Germany<br>
Journalist, Industry, Hong Kong/London.<br>
<a href="mailto:lies0002[AT]ntu[DOT]edu[DOT]sg">Get full CV</a><br>

<br />

<b>Publication:</b> <br />
<a href="https://scholar.google.com/citations?user=pMjOZNsAAAAJ">Visit Google scholar</a><br />
For the video corpus of spoken Chinese see also: <a href="https://liesenf.github.io/mycancor">MYCanCor</a><br />
For publications in Chinese see <a href="http://new.oversea.cnki.net/index/">CNKI</a><br />



<br />

<b>Software:</b><br>
<a href="https://liesenf.github.io/toolstutorials">Cause Chi</a> (Tagger for causal discourse markers in spoken Chinese)<br>
<a href="https://liesenf.github.io/toolstutorials">MV parser</a> (Argument structure tagger for Chinese) <br>

<br />

<b>Tutorials:</b><br>
<a href="https://liesenf.github.io/toolstutorials">Conversation analytic transcription in LaTeX</a><br>
<a href="https://liesenf.github.io/toolstutorials">Multilayed phonetic annotation with Praat</a><br>

<br />

<font color="red">&#9830; &#9830; &#9830; Website recently moved from www.andreasliesenfeld.com. I know its ugly. Sorry about that. &#9830; &#9830; &#9830;</font><br />

<br />
