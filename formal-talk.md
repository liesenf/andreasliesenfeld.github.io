---
layout: default
---

## Formal representations of talk for language technology

 <i> Keywords: theoretical computational linguistics *** NLP pipelines *** action and intent modeling </i>

** UNDER CONSTRUCTION **

### Introduction

Talk is interactionally accomplished as reflexive, ongoing and orderly sequences. But computational representations of talk do not take this into account. The use of formal represenations of language is to describe various aspects of talk-in-interaction for various scientific, technological or practical purposes, that is difficult enough. This series of projects is concerned with issues surrounding representations of talk as transcriptions or spectrograms for various language technology and science applications. How are representations used as part of different application? What is the relationship of the represenation to the real thing? How can we slice the representation into useful units for language technology applications and the study of talk?

### Graphical representatations of speech: The example of automatic speech recognition (ASR)

ASR is dead, long live ASR! Now that automatic speech recognition (ASR) has achieved "human-level performance" and Youtube can automatically create captions for any video, there has been a push to focus on all the other things that humans do in conversation - beyond clean, grammatical sentences. What about the astonishing amount of "uhs", "ahs", or "ohs" that people produce in talk? What about laughter, sighs, stutters and all the other exclamations and interjections?

### From commerical speech recognition to specialist speech recognition

Current speech recognition tech does not accurately transcribe and process these types of utterances, because that is not what the systems were designed for. In fact, commercial ASR is mostly designed to filter out disfluencies and non-lexical utterances, eliminating stutters, repairs or exclamations in speech and producing clean transcripts instead of accurately capturing these properties of speech. This can pose a limitation to the further processing of speaker input in interactive voice technology such as intent, stance or emotion recognition because non-lexical utterances are often meaningful rather than accidental and can play a role in the actions that speakers formulate.

Here are three example of verbal conduct that can commonly cause trouble for ASR systems:

#### Minimal particles

Short non-lexical vocalizations such as uhs ohs ahs are often transcribed in very course terms, collapsing a large range of variations under few tags or transcription formats. A large amount of phonetic and prosodic information is lost in such lexis or grapheme-based representations.

#### Laughter

Laughter can format a spectrum of action only sometimes related to humor. However, formal representions in ASR pipelines often reduce laughter to a simple tag.

### Towards more authentic prepresentions of verbal conduct

Different levels of representaional detail serve different uses. But some aspects of accurate representaions clearly remain underexplored.


#### Representaions beyond phonetic form: representations of meaning and function

 dialog flow prediction

prediction of adjacency pairs (question-response pairs) , TRPs and other sequencial patterns 

based on seq-to-seq models of spoken and subtitle corpora 


[back](./)
