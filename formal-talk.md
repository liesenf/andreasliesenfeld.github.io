---
layout: default
---

## Formal representations of talk for language technology

 <i> Keywords: theoretical computational linguistics *** formalisms *** NLP pipelines </i>

** UNDER CONSTRUCTION **

### Introduction

In the real world, talk is interactionally accomplished as reflexive, ongoing social conduct. Formal representations are designed to take some aspects of it into account as tools for the study and technology applications. Talk is more than spoken text. This project aims to illuminate some consequences that representations of talk are mere tools for learning and building. I aim to show implications of the limited means to formally represent talk for voice technology applications, the quantitative study of talk, and the possiblity of talking machines. 

### Reduce, count, automate

Formal represenations of language link up various aspects of talk-in-interaction to symbolic representations. This meakes talk computable and enables automation for various scientific or technological purposes. Text and speech processing pipelines rely on these representations to accomplish engineering task and enable automation. What are the limits of symbolic representations as appropriate representations of talk. What about higher dimensional\vector representations? How are representations used as part of different application? What is the relationship of the represenation to the real thing? And how can we slice the representation into useful units?

### Example 1: Graphical representatations of speech: The example of automatic speech recognition (ASR)

ASR is the task of automatically mapping audio recordings to textual transcription symbols using graphical representations of speech (spectrograms). 

### From commerical speech recognition to specialist speech recognition

ASR is dead, long live ASR! Now that automatic speech recognition (ASR) has achieved "human-level performance" and Youtube can automatically create captions for any video, there has been a push to focus on all the other things that humans do in conversation - beyond clean, grammatical sentences. What about the astonishing amount of "uhs", "ahs", or "ohs" that people produce in talk? What about laughter, sighs, stutters and all the other exclamations and interjections?

Current speech recognition tech does not accurately transcribe and process these types of utterances, because that is not what the systems were designed for. In fact, commercial ASR is mostly designed to filter out disfluencies and non-lexical utterances, eliminating stutters, repairs or exclamations in speech and producing clean transcripts instead of accurately capturing these properties of speech. This can pose a limitation to the further processing of speaker input in interactive voice technology such as intent, stance or emotion recognition because non-lexical utterances are often meaningful rather than accidental and can play a role in the actions that speakers formulate.

Here are three example of verbal conduct that can commonly cause trouble for ASR systems:

#### Minimal particles

Short non-lexical vocalizations such as uhs ohs ahs are often transcribed in very course terms, collapsing a large range of variations under few tags or transcription formats. A large amount of phonetic and prosodic information is lost in such lexis or grapheme-based representations.

#### Laughter

Laughter can format a spectrum of action only sometimes related to humor. However, formal representions in ASR pipelines often reduce laughter to a simple tag.


### Towards more authentic prepresentions of verbal conduct

Different levels of representaional detail serve different uses. But some aspects of accurate representaions clearly remain underexplored.


### Example 2: Representatations of meaning and function

TBC
 
 NLU
 
 dialog flow prediction

prediction of adjacency pairs (question-response pairs) , TRPs and other sequencial patterns 

based on seq-to-seq models of spoken and subtitle corpora 

Getting rid of intents?

[back](./)
