---
layout: default
---

## The "Beyond words speech recognition" project

 <i> Keywords: speech recognition *** minimal particles *** laughter </i>

** UNDER CONSTRUCTION **

ASR is dead, long live ASR! Now that automatic speech recognition (ASR) has achieved (post-)"human-level performance" and Youtube can automatically create captions for any video, research in the field increasingly focuses on all the other things  that humans utter in conversation - beyond clean, grammatical sentences. What about the astonishing amount of "uhs", "ahs", or "ohs" that people produce in talk? What about laughter, sighs, stutters and all the other exclamations and interjections? 
These utterances are often meaningful rather than accidental and can alter the actions that speakers formulate. Current speech recogntion tech, however, is notoriously bad at recognizing and transcribing such utterances, mainly because that is not what these commercial systems were designed for and because many systems are trained on clean audio-book data instead of on "messy" everyday talk. 

The aim of this 2-year project of the <a href="http://llt.cbs.polyu.edu.hk/">PolyU Linguistics Theory and Language Technology (LTT) group</a> in Hong Kong is to contribute to the development of more robust automatic speech recognition for processing non-lexical utterances, i.e. all utterances that are not clean, clear words. Focusing on everyday Chinese talk, the "Beyond words ASR" project involves both the exploratory analysis of talk-in-interaction with a focus on developing formal models of non-lexical utterances and their functions, and the incoporation of these models in current automatic speech recognition systems. There is more to speech recognition than the automatic creation of subtitles and we are just getting started to dig deeper into systematically transcribing and processing more aspects of real-world everyday conversations.


### Current speech recognition and the transcription of non-lexical utterances
conversation-analytic description of a "syntax" of talk-in-interaction, mostly focusing on its sequential unfolding:
 <a href="https://en.wikipedia.org/wiki/Ethnomethodology">ethnomethodology and conversation analysis</a> 
 
#### Minimal particles

#### Laughter

### Towards a more fine-grained automatic transcription of talk-in-interaction

#### Multilayered speech recognition

Quantitative inquiry (corpus-based analysis):
<a href="https://www.cambridge.org/core/journals/studies-in-second-language-acquisition/article/frequency-effects-in-language-processing/C4A2C08A0900E306078B9819D7ABF428
">Frequency effects in language processing</a> 

Link - live transcription by Google

Link - Natural action processing

[back](./)
