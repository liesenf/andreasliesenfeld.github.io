---
layout: default
---

## The "Beyond words speech recognition" project

 <i> Keywords: speech recognition *** minimal particles *** laughter </i>

** UNDER CONSTRUCTION **

ASR is dead, long live ASR! Now that automatic speech recognition (ASR) has achieved "human-level performance" and Youtube can automatically create captions for any video, research in the field increasingly focuses on all the other things that humans do in conversation - beyond clean, grammatical sentences. What about the astonishing amount of "uhs", "ahs", or "ohs" that people produce in talk? What about laughter, sighs, stutters and all the other exclamations and interjections? 
These utterances are often meaningful rather than accidental and can alter the actions that speakers formulate. Current speech recognition tech, however, is notoriously bad at recognizing these types of utterances, mainly because that is not what most commercial systems were designed for and because systems are trained on clean audio-book data instead of on "messy" everyday talk. 

The aim of this 2-year project of the <a href="http://llt.cbs.polyu.edu.hk/">PolyU Linguistics Theory and Language Technology (LTT) group</a> in Hong Kong is to contribute to the development of more robust automatic speech recognition for processing real-world everyday talk and especially non-lexical utterances, that is all utterances that are not clean, clear words. Focusing on everyday Chinese talk, the "Beyond words ASR" project involves both the exploratory analysis of talk-in-interaction with a focus on developing formal models of non-lexical utterances and their functions, and the incorporation of these models with current speech recognition systems. There is more to speech recognition than the automatic creation of subtitles and we are just getting started to dig deeper into systematically transcribing and processing more aspects of real-world everyday conversations.


### Current speech recognition and the transcription of non-lexical utterances

current speech tech is

all uhs ohs ahs get the same treatment, much phonetic and prosodic information is lost in lexis or grapheme-based models

laughter is also problematic because
 
#### Minimal particles

Example 1: minimal response tokens

Example 2: Ei surprise token

Example 3: Repair initiators

#### Laughter

Example 1: Laughter and humor

### Towards a more fine-grained automatic transcription of talk-in-interaction

action oriented, precise but functional

#### Multilayered speech recognition

Quantitative inquiry (corpus-based analysis):
<a href="https://www.cambridge.org/core/journals/studies-in-second-language-acquisition/article/frequency-effects-in-language-processing/C4A2C08A0900E306078B9819D7ABF428
">Frequency effects in language processing</a> 

Link - live transcription by Google

Link - Natural action processing

[back](./)
