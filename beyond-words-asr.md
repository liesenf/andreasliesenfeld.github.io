---
layout: default
---

## Speech recognition for conversation design

 <i> Keywords: automatic speech recognition *** talk-in-interaction *** action and intent modeling </i>

** UNDER CONSTRUCTION **

### Introduction

** UNDER CONSTRUCTION **



### From commerical speech recognition to specialist speech recognition

ASR is dead, long live ASR! Now that automatic speech recognition (ASR) has achieved "human-level performance" and Youtube can automatically create captions for any video, there has been a push to focus on all the other things that humans do in conversation - beyond clean, grammatical sentences. What about the astonishing amount of "uhs", "ahs", or "ohs" that people produce in talk? What about laughter, sighs, stutters and all the other exclamations and interjections? Current speech recognition tech does not accurately transcribe and process these types of utterances, because that is not what the systems were designed for. In fact, commercial ASR is mostly designed to filter out disfluencies and non-lexical utterances, eliminating stutters, repairs or exclamations in speech and producing clean transcripts instead of accurately capturing these properties of speech. This can pose a limitation to the further processing of speaker input in interactive voice technology such as intent, stance or emotion recognition because non-lexical utterances are often meaningful rather than accidental and can alter the actions that speakers formulate.

The aim of this 2-year project of the <a href="http://llt.cbs.polyu.edu.hk/">PolyU Linguistics Theory and Language Technology (LTT) group</a> in Hong Kong is to contribute to the development of automatic speech recognition for processing properties of real-world talk other than clean, clear words. Centered on colloquial Mandarin and Cantonese, the "Beyond words ASR" project involves both the empirical analysis of real-world conversation with a focus on developing formal models of non-lexical utterances and their incorporation with current speech recognition technology to advance the automatic transcription of additional properties of talk, beyond words.


### Speech recognition for conversation analysis and design

current speech tech is

all uhs ohs ahs get the same treatment, much phonetic and prosodic information is lost in lexis or grapheme-based models

laughter is also problematic because
 
#### Minimal particles

Example 1: minimal response tokens

Example 2: Ei surprise token

Example 3: Repair initiators

#### Laughter

Example 1: Laughter and humor

### Towards a more fine-grained automatic transcription of talk-in-interaction

action oriented, precise but functional

#### Multilayered speech recognition

Quantitative inquiry (corpus-based analysis):
<a href="https://www.cambridge.org/core/journals/studies-in-second-language-acquisition/article/frequency-effects-in-language-processing/C4A2C08A0900E306078B9819D7ABF428
">Frequency effects in language processing</a> 

Link - live transcription by Google

Link - Natural action processing

[back](./)
